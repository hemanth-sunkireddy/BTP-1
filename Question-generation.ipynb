{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f5e851a",
   "metadata": {},
   "source": [
    "## Generate Questions from Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05582b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "qg_pipeline = pipeline(\"text2text-generation\", model=\"valhalla/t5-base-qg-hl\")\n",
    "\n",
    "input_file = \"Data/sentences.txt\"\n",
    "output_file = \"Data/generated_questions.txt\"\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    sentences = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as out_file:\n",
    "    for sentence in tqdm(sentences, desc=\"Generating Questions\", unit=\"sentence\"):\n",
    "        questions = qg_pipeline(sentence, max_length=128, num_return_sequences=1)\n",
    "        for q in questions:\n",
    "            out_file.write(q[\"generated_text\"] + \"\\n\")  # Write each question on a new line\n",
    "\n",
    "print(\"Question generation complete! Questions saved in 'Data/generated_questions.txt'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ac5c9",
   "metadata": {},
   "source": [
    "## Create Embeddings for Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a86979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load the dataset\n",
    "questions_file = \"Data/generated_questions.txt\"\n",
    "questions = [line.strip() for line in open(questions_file, \"r\") if line.strip()]\n",
    "\n",
    "# Encode all questions\n",
    "question_embeddings = np.array(model.encode(questions)).astype(\"float32\")\n",
    "\n",
    "# Save embeddings and questions\n",
    "np.save(\"Data/questions_embeddings.npy\", question_embeddings)\n",
    "with open(\"questions_list.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(questions))\n",
    "\n",
    "print(\"Embeddings saved successfully to `questions_embeddings.npy` file!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30a4cfb",
   "metadata": {},
   "source": [
    "## Classify Question whether clear or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa182c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1. ðŸ“‚ Define local paths\n",
    "data_folder = \"Data\"\n",
    "embeddings_path = os.path.join(data_folder, \"questions_embeddings.npy\")\n",
    "questions_path = os.path.join(data_folder, \"questions_list.txt\")\n",
    "sentences_path = os.path.join(data_folder, \"sentences.txt\")\n",
    "faiss_index_path = os.path.join(data_folder, \"sentence_embeddings.index\")\n",
    "\n",
    "# 2. ðŸ¤– Load Sentence-BERT model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# 3. ðŸ“¥ Load question embeddings and questions\n",
    "question_embeddings = np.load(embeddings_path)\n",
    "\n",
    "# Load lecture sentences\n",
    "with open(sentences_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lecture_sentences = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Load FAISS index\n",
    "faiss_index = faiss.read_index(faiss_index_path)\n",
    "\n",
    "# 4. ðŸ” Similarity classification function\n",
    "def classify_question(query, threshold=0.60):\n",
    "    query_embedding = model.encode([query]).astype(\"float32\")\n",
    "    similarities = cosine_similarity(query_embedding, question_embeddings)[0]\n",
    "    max_similarity = np.max(similarities)\n",
    "    is_clear = max_similarity >= threshold\n",
    "    return (\"Clear\" if is_clear else \"Vague\"), max_similarity\n",
    "\n",
    "student_question = input(\"Enter your question: \")\n",
    "question_valid = classify_question(student_question)\n",
    "print(\"The question is: \", question_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
