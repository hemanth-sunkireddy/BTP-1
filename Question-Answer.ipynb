{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f5e851a",
   "metadata": {},
   "source": [
    "## Generate Questions from Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05582b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "qg_pipeline = pipeline(\"text2text-generation\", model=\"valhalla/t5-base-qg-hl\")\n",
    "\n",
    "input_file = \"Data/sentences.txt\"\n",
    "output_file = \"Data/generated_questions.txt\"\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    sentences = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as out_file:\n",
    "    for sentence in tqdm(sentences, desc=\"Generating Questions\", unit=\"sentence\"):\n",
    "        questions = qg_pipeline(sentence, max_length=128, num_return_sequences=1)\n",
    "        for q in questions:\n",
    "            out_file.write(q[\"generated_text\"] + \"\\n\")  # Write each question on a new line\n",
    "\n",
    "print(\"Question generation complete! Questions saved in 'Data/generated_questions.txt'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ac5c9",
   "metadata": {},
   "source": [
    "## Create Embeddings for Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a86979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load the dataset\n",
    "questions_file = \"Data/generated_questions.txt\"\n",
    "questions = [line.strip() for line in open(questions_file, \"r\") if line.strip()]\n",
    "\n",
    "# Encode all questions\n",
    "question_embeddings = np.array(model.encode(questions)).astype(\"float32\")\n",
    "\n",
    "# Save embeddings and questions\n",
    "np.save(\"Data/questions_embeddings.npy\", question_embeddings)\n",
    "with open(\"questions_list.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(questions))\n",
    "\n",
    "print(\"Embeddings saved successfully to `questions_embeddings.npy` file!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30a4cfb",
   "metadata": {},
   "source": [
    "## Classify Question whether clear or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa182c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1. ðŸ“‚ Define local paths\n",
    "data_folder = \"Data\"\n",
    "embeddings_path = os.path.join(data_folder, \"questions_embeddings.npy\")\n",
    "questions_path = os.path.join(data_folder, \"questions_list.txt\")\n",
    "sentences_path = os.path.join(data_folder, \"sentences.txt\")\n",
    "faiss_index_path = os.path.join(data_folder, \"sentence_embeddings.index\")\n",
    "\n",
    "# 2. ðŸ¤– Load Sentence-BERT model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# 3. ðŸ“¥ Load question embeddings and questions\n",
    "question_embeddings = np.load(embeddings_path)\n",
    "\n",
    "# Load lecture sentences\n",
    "with open(sentences_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lecture_sentences = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Load FAISS index\n",
    "faiss_index = faiss.read_index(faiss_index_path)\n",
    "\n",
    "# 4. ðŸ” Similarity classification function\n",
    "def classify_question(query, threshold=0.60):\n",
    "    query_embedding = model.encode([query]).astype(\"float32\")\n",
    "    similarities = cosine_similarity(query_embedding, question_embeddings)[0]\n",
    "    max_similarity = np.max(similarities)\n",
    "    is_clear = max_similarity >= threshold\n",
    "    return (\"Clear\" if is_clear else \"Vague\"), max_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec344a37",
   "metadata": {},
   "source": [
    "## Ask user Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9384abf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Related Sentences:\n",
      "- As you can see, machine learning is a top skill in the jobs that involves AI skills. - 0.5102\n",
      "- Machine learning consists of different types of learning, such as supervised learning, unsupervised learning, or reinforcement learning. - 0.5319\n",
      "- Many machine learning models, they are coming from statistical learning. - 0.5381\n",
      "- This video will talk about introduction to machine learning. - 0.5936\n",
      "- So machine learning is part of data science and it is also a subfield of artificial intelligence. - 0.6000\n",
      "- And here is the Google trend on the term on machine learning and software engineering. - 0.6220\n",
      "- So machine learning extends the statistical learning by including more complex algorithms, which deal with more complex data and bigger data, and more efficient algorithms. - 0.6400\n",
      "- Machine learning, we mentioned that machine learning several times during the talk about data science. - 0.6611\n",
      "- Here are some few examples of machine learning tasks. - 0.6639\n",
      "- It is one of the simplest kind of supervised learning model. - 0.6737\n",
      "- It focuses on learning algorithms and building models and training them on the data. - 0.6887\n",
      "\n",
      "Related Sentences with Metadata:\n",
      "- [1.srt] [00:05:56.820 --> 00:06:06.550] As you can see, machine learning is a top skill in the jobs that involves AI skills. - Distance: 0.5102\n",
      "- [1.srt] [00:02:49.840 --> 00:02:54.140] Machine learning consists of different types of learning, such as supervised learning, unsupervised learning, or reinforcement learning. - Distance: 0.5319\n",
      "- [1.srt] [00:02:55.280 --> 00:03:02.489] Many machine learning models, they are coming from statistical learning. - Distance: 0.5381\n",
      "- [1.srt] [00:00:05.610 --> 00:00:07.580] This video will talk about introduction to machine learning. - Distance: 0.5936\n",
      "- [1.srt] [00:02:37.450 --> 00:02:42.409] So machine learning is part of data science and it is also a subfield of artificial intelligence. - Distance: 0.6000\n",
      "- [1.srt] [00:05:27.620 --> 00:05:33.500] And here is the Google trend on the term on machine learning and software engineering. - Distance: 0.6220\n",
      "- [1.srt] [00:03:03.539 --> 00:03:06.799] So machine learning extends the statistical learning by including more complex algorithms, which deal with more complex data and bigger data, and more efficient algorithms. - Distance: 0.6400\n",
      "- [1.srt] [00:02:28.590 --> 00:02:35.590] Machine learning, we mentioned that machine learning several times during the talk about data science. - Distance: 0.6611\n",
      "- [1.srt] [00:12:49.830 --> 00:13:01.400] Here are some few examples of machine learning tasks. - Distance: 0.6639\n",
      "- [2.srt] [00:01:19.590 --> 00:01:21.189] It is one of the simplest kind of supervised learning model. - Distance: 0.6737\n",
      "- [1.srt] [00:02:42.550 --> 00:02:48.879] It focuses on learning algorithms and building models and training them on the data. - Distance: 0.6887\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import csv\n",
    "\n",
    "# Load the model and FAISS index\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "faiss_index = faiss.read_index(\"Data/sentence_embeddings.index\")\n",
    "\n",
    "# Load lecture sentences\n",
    "with open('Data/sentences.txt', 'r') as file:\n",
    "    lecture_sentences = file.readlines()\n",
    "lecture_sentences = [line.strip() for line in lecture_sentences if line.strip()]\n",
    "\n",
    "lecture_data = []\n",
    "with open('Data/srt-embedding-metadata.tsv', 'r', encoding='utf-8') as file:\n",
    "    tsv_reader = csv.reader(file, delimiter='\\t')\n",
    "    for row in tsv_reader:\n",
    "        if len(row) == 3:\n",
    "            filename, timestamp, sentence = row\n",
    "            lecture_data.append((filename.strip(), timestamp.strip(), sentence.strip()))\n",
    "\n",
    "# Get student's question\n",
    "student_question = input(\"Enter your question: \")\n",
    "question_embedding = np.array(model.encode([student_question])).astype('float32')\n",
    "\n",
    "# Search all sentences (max number can be total sentences in the index)\n",
    "distances, indices = faiss_index.search(question_embedding, len(lecture_sentences))\n",
    "\n",
    "# Define a distance threshold (lower means more similar)\n",
    "distance_threshold = 0.7\n",
    "\n",
    "related_sentences = []\n",
    "related_results = []\n",
    "for j in range(len(indices[0])):\n",
    "    i = indices[0][j]\n",
    "    distance = distances[0][j]\n",
    "    sentence = lecture_sentences[i]\n",
    "    \n",
    "    # Check if the sentence is below the distance threshold and is not a question\n",
    "    if distance > 0 and distance <= distance_threshold and not sentence.strip().endswith('?'):\n",
    "        related_sentences.append((sentence, distance))\n",
    "        filename, timestamp, _ = lecture_data[i]\n",
    "        related_results.append((filename, timestamp, sentence, distance))\n",
    "\n",
    "\n",
    "# Display related sentences with distances\n",
    "print(\"\\n Related Sentences:\")\n",
    "for sentence, distance in related_sentences:\n",
    "    print(f\"- {sentence} - {distance:.4f}\")\n",
    "\n",
    "print(\"\\nRelated Sentences with Metadata:\")\n",
    "for filename, timestamp, sentence, distance in related_results:\n",
    "    print(f\"- [{filename}] [{timestamp}] {sentence} - Distance: {distance:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
