{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f5e851a",
   "metadata": {},
   "source": [
    "## Generate Questions from Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05582b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "qg_pipeline = pipeline(\"text2text-generation\", model=\"valhalla/t5-base-qg-hl\")\n",
    "\n",
    "input_file = \"Data/sentences.txt\"\n",
    "output_file = \"Data/generated_questions.txt\"\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    sentences = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as out_file:\n",
    "    for sentence in tqdm(sentences, desc=\"Generating Questions\", unit=\"sentence\"):\n",
    "        questions = qg_pipeline(sentence, max_length=128, num_return_sequences=1)\n",
    "        for q in questions:\n",
    "            out_file.write(q[\"generated_text\"] + \"\\n\")  # Write each question on a new line\n",
    "\n",
    "print(\"Question generation complete! Questions saved in 'Data/generated_questions.txt'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ac5c9",
   "metadata": {},
   "source": [
    "## Create Embeddings for Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69a86979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved successfully to `questions_embeddings.npy` file!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load the dataset\n",
    "questions_file = \"Data/generated_questions.txt\"\n",
    "questions = [line.strip() for line in open(questions_file, \"r\") if line.strip()]\n",
    "\n",
    "# Encode all questions\n",
    "question_embeddings = np.array(model.encode(questions)).astype(\"float32\")\n",
    "\n",
    "# Save embeddings and questions\n",
    "np.save(\"Data/questions_embeddings.npy\", question_embeddings)\n",
    "with open(\"questions_list.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(questions))\n",
    "\n",
    "print(\"Embeddings saved successfully to `questions_embeddings.npy` file!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30a4cfb",
   "metadata": {},
   "source": [
    "## Classify Question whether clear or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa182c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1. 📂 Define local paths\n",
    "data_folder = \"Data\"\n",
    "embeddings_path = os.path.join(data_folder, \"questions_embeddings.npy\")\n",
    "questions_path = os.path.join(data_folder, \"questions_list.txt\")\n",
    "sentences_path = os.path.join(data_folder, \"sentences.txt\")\n",
    "faiss_index_path = os.path.join(data_folder, \"sentence_embeddings.index\")\n",
    "\n",
    "# 2. 🤖 Load Sentence-BERT model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# 3. 📥 Load question embeddings and questions\n",
    "question_embeddings = np.load(embeddings_path)\n",
    "\n",
    "# Load lecture sentences\n",
    "with open(sentences_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lecture_sentences = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Load FAISS index\n",
    "faiss_index = faiss.read_index(faiss_index_path)\n",
    "\n",
    "# 4. 🔍 Similarity classification function\n",
    "def classify_question(query, threshold=0.60):\n",
    "    query_embedding = model.encode([query]).astype(\"float32\")\n",
    "    similarities = cosine_similarity(query_embedding, question_embeddings)[0]\n",
    "    max_similarity = np.max(similarities)\n",
    "    is_clear = max_similarity >= threshold\n",
    "    return (\"Clear\" if is_clear else \"Vague\"), max_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec344a37",
   "metadata": {},
   "source": [
    "## Ask user Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9384abf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Your question is clear (Similarity: 1.00). Proceeding with the answer...\n",
      "Question: What is Machine Learning?\n",
      "\n",
      "🔎 Related Sentences:\n",
      "- 📁 1.srt 🕒 00:06:07.960 --> 00:06:12.370\n",
      "  💬 As you can see, machine learning is a top skill in the jobs that involves AI skills. (Distance: 0.5102)\n",
      "\n",
      "- 📁 1.srt 🕒 00:02:55.280 --> 00:03:02.489\n",
      "  💬 Machine learning consists of different types of learning, such as supervised learning, unsupervised learning, or reinforcement learning. (Distance: 0.5319)\n",
      "\n",
      "- 📁 1.srt 🕒 00:03:03.539 --> 00:03:06.799\n",
      "  💬 Many machine learning models, they are coming from statistical learning. (Distance: 0.5381)\n",
      "\n",
      "- 📁 1.srt 🕒 00:00:07.940 --> 00:00:11.130\n",
      "  💬 This video will talk about introduction to machine learning. (Distance: 0.5936)\n",
      "\n",
      "- 📁 1.srt 🕒 00:02:42.550 --> 00:02:48.879\n",
      "  💬 So machine learning is part of data science and it is also a subfield of artificial intelligence. (Distance: 0.6000)\n",
      "\n",
      "- 📁 1.srt 🕒 00:05:36.290 --> 00:05:41.000\n",
      "  💬 And here is the Google trend on the term on machine learning and software engineering. (Distance: 0.6220)\n",
      "\n",
      "- 📁 1.srt 🕒 00:03:07.229 --> 00:03:17.589\n",
      "  💬 So machine learning extends the statistical learning by including more complex algorithms, which deal with more complex data and bigger data, and more efficient algorithms. (Distance: 0.6400)\n",
      "\n",
      "- 📁 1.srt 🕒 00:02:37.450 --> 00:02:42.409\n",
      "  💬 Machine learning, we mentioned that machine learning several times during the talk about data science. (Distance: 0.6611)\n",
      "\n",
      "- 📁 1.srt 🕒 00:13:03.110 --> 00:13:05.670\n",
      "  💬 Here are some few examples of machine learning tasks. (Distance: 0.6639)\n",
      "\n",
      "- 📁 2.srt 🕒 00:01:21.239 --> 00:01:24.949\n",
      "  💬 It is one of the simplest kind of supervised learning model. (Distance: 0.6737)\n",
      "\n",
      "- 📁 1.srt 🕒 00:02:49.840 --> 00:02:54.140\n",
      "  💬 It focuses on learning algorithms and building models and training them on the data. (Distance: 0.6887)\n",
      "\n",
      "✅ Your question is clear (Similarity: 0.99). Proceeding with the answer...\n",
      "Question: What is Linear Regression?\n",
      "\n",
      "🔎 Related Sentences:\n",
      "- 📁 2.srt 🕒 00:00:06.419 --> 00:00:08.929\n",
      "  💬 In this video, we're going to talk about linear regression. (Distance: 0.4420)\n",
      "\n",
      "- 📁 2.srt 🕒 00:04:22.079 --> 00:04:34.989\n",
      "  💬 So this type of model, whether we have many variables or one variable, that shows some linear relationship of the variable to the target and this type of model is called the linear regression. (Distance: 0.4432)\n",
      "\n",
      "- 📁 23.srt 🕒 00:00:49.750 --> 00:00:53.390\n",
      "  💬 So for example, linear regression applies to regression problems. (Distance: 0.5935)\n",
      "\n",
      "- 📁 2.srt 🕒 00:00:09.619 --> 00:00:17.170\n",
      "  💬 So we'll begin by the definition of linear regression, and we'll talk about how this model can optimize to get the best estimate value. (Distance: 0.6164)\n",
      "\n",
      "- 📁 23.srt 🕒 00:03:32.740 --> 00:03:34.519\n",
      "  💬 And linear regression has parameters. (Distance: 0.6644)\n",
      "\n",
      "- 📁 5.srt 🕒 00:18:18.319 --> 00:18:21.160\n",
      "  💬 And that's it for the simple linear regression. (Distance: 0.6766)\n",
      "\n",
      "- 📁 6.srt 🕒 00:02:09.330 --> 00:02:16.219\n",
      "  💬 So this is also linear regression especially it's called multi linear regression because it has multiple features. (Distance: 0.6799)\n",
      "\n",
      "⚠️ Your question seems unclear (Similarity: 0.49). Please provide more details.\n",
      "⚠️ Your question seems unclear (Similarity: 0.49). Please provide more details.\n",
      "👋 Exiting...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load model and metadata\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # or your preferred model\n",
    "metadata_df = pd.read_csv('Data/srt-embedding-metadata.tsv', sep='\\t')\n",
    "lecture_sentences = metadata_df['sentence'].tolist()\n",
    "\n",
    "# Build FAISS index (only once at startup)\n",
    "sentence_embeddings = model.encode(lecture_sentences).astype('float32')\n",
    "faiss_index = faiss.IndexFlatL2(sentence_embeddings.shape[1])\n",
    "faiss_index.add(sentence_embeddings)\n",
    "\n",
    "\n",
    "# Interactive loop\n",
    "while True:\n",
    "    student_question = input(\"\\n📩 Enter your question (or type 'exit' to quit): \").strip()\n",
    "    if student_question.lower() == 'exit':\n",
    "        print(\"👋 Exiting...\")\n",
    "        break\n",
    "\n",
    "    status, score = classify_question(student_question)\n",
    "\n",
    "    if status == \"Vague\":\n",
    "        print(f\"⚠️ Your question seems unclear (Similarity: {score:.2f}). Please provide more details.\")\n",
    "    else:\n",
    "        print(f\"✅ Your question is clear (Similarity: {score:.2f}). Proceeding with the answer...\")\n",
    "\n",
    "        # Encode student question and search FAISS index\n",
    "        question_embedding = model.encode([student_question]).astype('float32')\n",
    "        distances, indices = faiss_index.search(question_embedding, len(lecture_sentences))\n",
    "\n",
    "        distance_threshold = 0.7\n",
    "        related_sentences = [\n",
    "            (\n",
    "                metadata_df.iloc[i][\"sentence\"],\n",
    "                metadata_df.iloc[i][\"filename\"],\n",
    "                metadata_df.iloc[i][\"timestamp\"],\n",
    "                distances[0][j]\n",
    "            )\n",
    "            for j, i in enumerate(indices[0])\n",
    "            if 0 < distances[0][j] <= distance_threshold and not metadata_df.iloc[i][\"sentence\"].endswith('?')\n",
    "        ]\n",
    "\n",
    "        print(\"Question:\", student_question)\n",
    "        print(\"\\n🔎 Related Sentences:\")\n",
    "        if not related_sentences:\n",
    "            print(\"❌ No related sentences found...\")\n",
    "        else:\n",
    "            for sentence, filename, timestamp, distance in related_sentences:\n",
    "                print(f\"- 📁 {filename} 🕒 {timestamp}\\n  💬 {sentence} (Distance: {distance:.4f})\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
