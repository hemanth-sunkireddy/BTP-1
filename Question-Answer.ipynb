{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f5e851a",
   "metadata": {},
   "source": [
    "## Generate Questions from Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05582b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "qg_pipeline = pipeline(\"text2text-generation\", model=\"valhalla/t5-base-qg-hl\")\n",
    "\n",
    "input_file = \"Data/sentences.txt\"\n",
    "output_file = \"Data/generated_questions.txt\"\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    sentences = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as out_file:\n",
    "    for sentence in tqdm(sentences, desc=\"Generating Questions\", unit=\"sentence\"):\n",
    "        questions = qg_pipeline(sentence, max_length=128, num_return_sequences=1)\n",
    "        for q in questions:\n",
    "            out_file.write(q[\"generated_text\"] + \"\\n\")  # Write each question on a new line\n",
    "\n",
    "print(\"Question generation complete! Questions saved in 'Data/generated_questions.txt'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ac5c9",
   "metadata": {},
   "source": [
    "## Create Embeddings for Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69a86979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved successfully to `questions_embeddings.npy` file!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load the dataset\n",
    "questions_file = \"Data/generated_questions.txt\"\n",
    "questions = [line.strip() for line in open(questions_file, \"r\") if line.strip()]\n",
    "\n",
    "# Encode all questions\n",
    "question_embeddings = np.array(model.encode(questions)).astype(\"float32\")\n",
    "\n",
    "# Save embeddings and questions\n",
    "np.save(\"Data/questions_embeddings.npy\", question_embeddings)\n",
    "with open(\"questions_list.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(questions))\n",
    "\n",
    "print(\"Embeddings saved successfully to `questions_embeddings.npy` file!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30a4cfb",
   "metadata": {},
   "source": [
    "## Classify Question whether clear or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa182c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1. üìÇ Define local paths\n",
    "data_folder = \"Data\"\n",
    "embeddings_path = os.path.join(data_folder, \"questions_embeddings.npy\")\n",
    "questions_path = os.path.join(data_folder, \"questions_list.txt\")\n",
    "sentences_path = os.path.join(data_folder, \"sentences.txt\")\n",
    "faiss_index_path = os.path.join(data_folder, \"sentence_embeddings.index\")\n",
    "\n",
    "# 2. ü§ñ Load Sentence-BERT model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# 3. üì• Load question embeddings and questions\n",
    "question_embeddings = np.load(embeddings_path)\n",
    "\n",
    "# Load lecture sentences\n",
    "with open(sentences_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lecture_sentences = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Load FAISS index\n",
    "faiss_index = faiss.read_index(faiss_index_path)\n",
    "\n",
    "# 4. üîç Similarity classification function\n",
    "def classify_question(query, threshold=0.60):\n",
    "    query_embedding = model.encode([query]).astype(\"float32\")\n",
    "    similarities = cosine_similarity(query_embedding, question_embeddings)[0]\n",
    "    max_similarity = np.max(similarities)\n",
    "    is_clear = max_similarity >= threshold\n",
    "    return (\"Clear\" if is_clear else \"Vague\"), max_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec344a37",
   "metadata": {},
   "source": [
    "## Ask user Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9384abf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Your question is clear (Similarity: 1.00). Proceeding with the answer...\n",
      "Question: What is Machine Learning?\n",
      "\n",
      "üîé Related Sentences:\n",
      "- üìÅ 1.srt üïí 00:06:07.960 --> 00:06:12.370\n",
      "  üí¨ As you can see, machine learning is a top skill in the jobs that involves AI skills. (Distance: 0.5102)\n",
      "\n",
      "- üìÅ 1.srt üïí 00:02:55.280 --> 00:03:02.489\n",
      "  üí¨ Machine learning consists of different types of learning, such as supervised learning, unsupervised learning, or reinforcement learning. (Distance: 0.5319)\n",
      "\n",
      "- üìÅ 1.srt üïí 00:03:03.539 --> 00:03:06.799\n",
      "  üí¨ Many machine learning models, they are coming from statistical learning. (Distance: 0.5381)\n",
      "\n",
      "- üìÅ 1.srt üïí 00:00:07.940 --> 00:00:11.130\n",
      "  üí¨ This video will talk about introduction to machine learning. (Distance: 0.5936)\n",
      "\n",
      "- üìÅ 1.srt üïí 00:02:42.550 --> 00:02:48.879\n",
      "  üí¨ So machine learning is part of data science and it is also a subfield of artificial intelligence. (Distance: 0.6000)\n",
      "\n",
      "- üìÅ 1.srt üïí 00:05:36.290 --> 00:05:41.000\n",
      "  üí¨ And here is the Google trend on the term on machine learning and software engineering. (Distance: 0.6220)\n",
      "\n",
      "- üìÅ 1.srt üïí 00:03:07.229 --> 00:03:17.589\n",
      "  üí¨ So machine learning extends the statistical learning by including more complex algorithms, which deal with more complex data and bigger data, and more efficient algorithms. (Distance: 0.6400)\n",
      "\n",
      "- üìÅ 1.srt üïí 00:02:37.450 --> 00:02:42.409\n",
      "  üí¨ Machine learning, we mentioned that machine learning several times during the talk about data science. (Distance: 0.6611)\n",
      "\n",
      "- üìÅ 1.srt üïí 00:13:03.110 --> 00:13:05.670\n",
      "  üí¨ Here are some few examples of machine learning tasks. (Distance: 0.6639)\n",
      "\n",
      "- üìÅ 2.srt üïí 00:01:21.239 --> 00:01:24.949\n",
      "  üí¨ It is one of the simplest kind of supervised learning model. (Distance: 0.6737)\n",
      "\n",
      "- üìÅ 1.srt üïí 00:02:49.840 --> 00:02:54.140\n",
      "  üí¨ It focuses on learning algorithms and building models and training them on the data. (Distance: 0.6887)\n",
      "\n",
      "‚úÖ Your question is clear (Similarity: 0.99). Proceeding with the answer...\n",
      "Question: What is Linear Regression?\n",
      "\n",
      "üîé Related Sentences:\n",
      "- üìÅ 2.srt üïí 00:00:06.419 --> 00:00:08.929\n",
      "  üí¨ In this video, we're going to talk about linear regression. (Distance: 0.4420)\n",
      "\n",
      "- üìÅ 2.srt üïí 00:04:22.079 --> 00:04:34.989\n",
      "  üí¨ So this type of model, whether we have many variables or one variable, that shows some linear relationship of the variable to the target and this type of model is called the linear regression. (Distance: 0.4432)\n",
      "\n",
      "- üìÅ 23.srt üïí 00:00:49.750 --> 00:00:53.390\n",
      "  üí¨ So for example, linear regression applies to regression problems. (Distance: 0.5935)\n",
      "\n",
      "- üìÅ 2.srt üïí 00:00:09.619 --> 00:00:17.170\n",
      "  üí¨ So we'll begin by the definition of linear regression, and we'll talk about how this model can optimize to get the best estimate value. (Distance: 0.6164)\n",
      "\n",
      "- üìÅ 23.srt üïí 00:03:32.740 --> 00:03:34.519\n",
      "  üí¨ And linear regression has parameters. (Distance: 0.6644)\n",
      "\n",
      "- üìÅ 5.srt üïí 00:18:18.319 --> 00:18:21.160\n",
      "  üí¨ And that's it for the simple linear regression. (Distance: 0.6766)\n",
      "\n",
      "- üìÅ 6.srt üïí 00:02:09.330 --> 00:02:16.219\n",
      "  üí¨ So this is also linear regression especially it's called multi linear regression because it has multiple features. (Distance: 0.6799)\n",
      "\n",
      "‚ö†Ô∏è Your question seems unclear (Similarity: 0.49). Please provide more details.\n",
      "‚ö†Ô∏è Your question seems unclear (Similarity: 0.49). Please provide more details.\n",
      "üëã Exiting...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load model and metadata\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # or your preferred model\n",
    "metadata_df = pd.read_csv('Data/srt-embedding-metadata.tsv', sep='\\t')\n",
    "lecture_sentences = metadata_df['sentence'].tolist()\n",
    "\n",
    "# Build FAISS index (only once at startup)\n",
    "sentence_embeddings = model.encode(lecture_sentences).astype('float32')\n",
    "faiss_index = faiss.IndexFlatL2(sentence_embeddings.shape[1])\n",
    "faiss_index.add(sentence_embeddings)\n",
    "\n",
    "\n",
    "# Interactive loop\n",
    "while True:\n",
    "    student_question = input(\"\\nüì© Enter your question (or type 'exit' to quit): \").strip()\n",
    "    if student_question.lower() == 'exit':\n",
    "        print(\"üëã Exiting...\")\n",
    "        break\n",
    "\n",
    "    status, score = classify_question(student_question)\n",
    "\n",
    "    if status == \"Vague\":\n",
    "        print(f\"‚ö†Ô∏è Your question seems unclear (Similarity: {score:.2f}). Please provide more details.\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Your question is clear (Similarity: {score:.2f}). Proceeding with the answer...\")\n",
    "\n",
    "        # Encode student question and search FAISS index\n",
    "        question_embedding = model.encode([student_question]).astype('float32')\n",
    "        distances, indices = faiss_index.search(question_embedding, len(lecture_sentences))\n",
    "\n",
    "        distance_threshold = 0.7\n",
    "        related_sentences = [\n",
    "            (\n",
    "                metadata_df.iloc[i][\"sentence\"],\n",
    "                metadata_df.iloc[i][\"filename\"],\n",
    "                metadata_df.iloc[i][\"timestamp\"],\n",
    "                distances[0][j]\n",
    "            )\n",
    "            for j, i in enumerate(indices[0])\n",
    "            if 0 < distances[0][j] <= distance_threshold and not metadata_df.iloc[i][\"sentence\"].endswith('?')\n",
    "        ]\n",
    "\n",
    "        print(\"Question:\", student_question)\n",
    "        print(\"\\nüîé Related Sentences:\")\n",
    "        if not related_sentences:\n",
    "            print(\"‚ùå No related sentences found...\")\n",
    "        else:\n",
    "            for sentence, filename, timestamp, distance in related_sentences:\n",
    "                print(f\"- üìÅ {filename} üïí {timestamp}\\n  üí¨ {sentence} (Distance: {distance:.4f})\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
