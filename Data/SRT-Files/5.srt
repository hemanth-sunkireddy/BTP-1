1
00:00:10,070 --> 00:00:13,609
Okay, so let's talk about how significant the coefficient values are.

2
00:00:15,509 --> 00:00:18,449
So when do you say the coefficient values are significant?

3
00:00:18,940 --> 00:00:25,429
And conversely, when can we say that the coefficient value is not significant?

4
00:00:26,760 --> 00:00:36,060
So think about this, when the coefficient value is not significant, that means we picked up some kind of noise from the data and assign some value for coefficients.

5
00:00:36,419 --> 00:00:38,899
when in fact the coefficient value is zero.

6
00:00:39,890 --> 00:00:47,669
So when you hear coefficient value is not significant, that means the coefficient value should be actually zero.

7
00:00:50,409 --> 00:00:53,379
So let's look at this coefficient value.

8
00:00:53,429 --> 00:00:58,759
It's minus 4000 something and it's a 280 something.

9
00:00:59,619 --> 00:01:04,719
So that looks like that's very big number, big difference from zero.

10
00:01:04,719 --> 00:01:09,469
So maybe we can, can you just say my coefficient values are all significant.

11
00:01:11,489 --> 00:01:35,530
So the absolute value of the coefficient value is not enough to say whether it's significant or not, because consider we change the unit of this target variable, then we can suddenly have a very small coefficient number, and it's hard to tell then whether this number should be zero or not.

12
00:01:36,419 --> 00:01:39,530
So we need some comparison.

13
00:01:39,829 --> 00:01:43,929
We need some way to compare whether this number is good enough or not.

14
00:01:43,929 --> 00:01:48,729
And usually the standard error is a good way to tell it.

15
00:01:48,729 --> 00:02:05,409
So that means if my coefficient value is maybe here, let's say mu, average of my coefficient value is here and this is zero.

16
00:02:05,879 --> 00:02:10,319
And we want to know how far away is my average coefficient value.

17
00:02:12,580 --> 00:02:15,930
And also we want to know how much of spread I have.

18
00:02:16,860 --> 00:02:28,150
So if the spread is pretty large like this, then maybe this mean value for my coefficient isn't very real.

19
00:02:28,729 --> 00:02:45,020
However, if I have this sharp distribution that essentially says my spread of my values for the coefficients are this small and this far away from

20
00:02:45,229 --> 00:02:51,500
zero, then I can say with the confidence that my coefficient value is actually real.

21
00:02:51,840 --> 00:03:02,259
So we're going to talk about this and all these values that shows here are good measure of those confidence or statistical significance.

22
00:03:02,879 --> 00:03:03,740
So let's dive in.

23
00:03:04,759 --> 00:03:11,060
So we mentioned that it is important to know the standard error or the spread of my coefficient value.

24
00:03:13,379 --> 00:03:16,240
And there are different ways to get the

25
00:03:16,629 --> 00:03:19,869
standard error or the spread of my coefficient value.

26
00:03:20,089 --> 00:03:33,519
One is using some theory or assumption that the residual is some normal distribution with the zero mean and certain spread or variance.

27
00:03:34,389 --> 00:03:45,949
Another way to do that is we just resample the data multiple times and then fit onto that data and get the coefficient value and we do that experiment multiple times.

28
00:03:46,589 --> 00:03:52,609
then we can get the standard error of my coefficients and all kinds of statistical values from there.

29
00:03:53,579 --> 00:03:56,869
But let's briefly talk about what this model-based method is.

30
00:03:56,869 --> 00:04:12,179
So VIRAR derivation, this is called the covariance matrix, which is variance of beta zero, variance of beta one, and covariance of beta zero and beta one.

31
00:04:12,179 --> 00:04:14,939
So matrix looks like this.

32
00:04:24,739 --> 00:04:28,729
But however, we don't have to remember all this math.

33
00:04:29,119 --> 00:04:36,369
This is given by this formula and this leads to the standard error value for intercept and slope.

34
00:04:36,469 --> 00:04:38,479
It looks like this.

35
00:04:38,479 --> 00:04:40,849
However, we don't have to remember all this formula.

36
00:04:41,309 --> 00:04:54,319
But important thing to remember is that all of this variance or standard error value is proportional to the variance of the residual.

37
00:04:54,989 --> 00:05:06,250
So that means if I have data that has a large spread like this, then it's likely that my coefficient values also have a large spread.

38
00:05:07,370 --> 00:05:17,359
And also you can see that the spread of the coefficients not only depends on this variance of the residuals, but also the variance of the data itself.

39
00:05:19,909 --> 00:05:22,599
This model assumes a homoscedasticity.

40
00:05:23,169 --> 00:05:24,289
That means

41
00:05:24,609 --> 00:05:28,889
the spread of the data is kind of homogeneous over the data.

42
00:05:29,870 --> 00:05:35,439
However, if you look at our data, that looks like some kind of cone shape like this.

43
00:05:37,429 --> 00:05:43,439
The residual, the spread of the residual is not homogeneous.

44
00:05:43,949 --> 00:05:49,810
However, we can still assume this model and then derive the quantities that we need.

45
00:05:54,699 --> 00:05:56,629
If you are not convinced by that,

46
00:05:56,839 --> 00:06:01,659
the model's assumption, then maybe we can use bootstrapping method.

47
00:06:02,149 --> 00:06:05,550
So bootstrapping method is resampling method.

48
00:06:06,490 --> 00:06:10,639
So let's say we have data point that looks like this originally.

49
00:06:14,589 --> 00:06:22,919
Then we can sample some experiment that samples some of the data point like this.

50
00:06:25,849 --> 00:06:29,169
And then we can have that and then

51
00:06:29,460 --> 00:06:37,650
draw another one that samples this data.

52
00:06:44,040 --> 00:06:44,540
And so on.

53
00:06:44,540 --> 00:06:46,550
And we can have multiple copies of this.

54
00:06:46,949 --> 00:06:49,519
We can have many many samples that we want.

55
00:06:49,720 --> 00:06:53,980
We can even sample the same data twice or multiple times.

56
00:06:54,120 --> 00:06:55,460
It doesn't matter.

57
00:06:55,590 --> 00:06:59,550
We can have some sampling with the replacement.

58
00:07:00,780 --> 00:07:12,500
So let's say we have many data like that and then we can fit the coefficient values and this coefficient value will be different from this one slightly but they will be similar.

59
00:07:12,920 --> 00:07:23,910
So we get all these values then we can get the mean value of this as well as the standard deviation or variance of that value.

60
00:07:26,650 --> 00:07:31,240
Alright so that's how we get standard error for the coefficient values.

61
00:07:32,500 --> 00:07:38,560
So let's talk about how we determine whether our coefficient values are statistically significant.

62
00:07:39,139 --> 00:07:41,310
To do that, we're going to do the hypothesis testing.

63
00:07:42,170 --> 00:07:52,439
With the two hypothesis, the null hypothesis say that our coefficient value is 0 and the alternate hypothesis saying that our coefficient value is not 0.

64
00:07:53,560 --> 00:07:57,660
And to test that, we're going to construct a t-score which is given by this.

65
00:07:57,660 --> 00:08:00,000
The t-score is standardized.

66
00:08:03,770 --> 00:08:14,980
our coefficient value, estimate value, by subtracting the mean which is given by our hypothesis and the standard error of our estimated coefficient.

67
00:08:16,290 --> 00:08:29,319
This is similar to G-score in normal distribution and actually when the number of samples is larger than 30, the t-distribution approximate to normal distribution so they are essentially the same most of cases.

68
00:08:29,319 --> 00:08:32,860
We're going to calculate the p-value and

69
00:08:35,850 --> 00:08:37,269
We can briefly review.

70
00:08:38,209 --> 00:08:44,049
So let's say we have a standard normal distribution like this.

71
00:08:45,049 --> 00:08:48,350
This is zero mean and has a unit variance.

72
00:08:49,309 --> 00:08:52,059
And then let's say we want to have a 5% of error rate.

73
00:08:53,090 --> 00:09:05,909
So that gives us critical value which defines that this area within these critical values.

74
00:09:06,309 --> 00:09:12,039
plus 1.96 and minus 1.96 for standard normal distribution.

75
00:09:12,039 --> 00:09:27,600
This area is 0.95 and the rest, this region and that region, the combined area would be 0.05.

76
00:09:27,600 --> 00:09:31,909
So that's our error rate and this value is also called alpha.

77
00:09:31,909 --> 00:09:35,470
And in standard normal distribution,

78
00:09:37,679 --> 00:09:57,779
this shaded area are symmetric, so each of them is going to be 0.025 0.025 and then we're going to have p-value according to our t-score.

79
00:09:58,139 --> 00:10:06,469
So whenever our t-score lies in the rejection region which is shaded in this red area,

80
00:10:09,769 --> 00:10:13,359
or maybe here, then we can reject the null hypothesis.

81
00:10:15,359 --> 00:10:16,449
And what is the p-value here?

82
00:10:16,449 --> 00:10:29,989
p-value is this area under the curve enclosed by this t-score or this area in case the t-score was negative.

83
00:10:29,989 --> 00:10:36,109
In that case, in this particular example, our p-value is smaller than the

84
00:10:40,709 --> 00:10:42,209
half of the alpha.

85
00:10:42,889 --> 00:10:51,329
So this green area is smaller than the rejection area and in that case, our t-score lies in the rejection region.

86
00:10:51,329 --> 00:10:54,899
Therefore, we can reject the null hypothesis.

87
00:10:54,899 --> 00:11:01,230
What if our t-score lied in here?

88
00:11:01,230 --> 00:11:08,929
Then again, our p-value will be this big.

89
00:11:08,929 --> 00:11:13,919
So when our p-value is bigger than the half of the alpha,

90
00:11:15,259 --> 00:11:17,220
we cannot reject the null hypothesis.

91
00:11:19,649 --> 00:11:25,389
All right, so let's see if we can reject the null hypothesis from our regression result.

92
00:11:27,710 --> 00:11:29,980
So that looks like this.

93
00:11:32,170 --> 00:11:46,340
When we look at the t value, it's minus 10, I'm gonna change my color, it's minus 10 sigma away from the mean and for the intercept and for the slope, it's 145 sigma away from the mean.

94
00:11:46,340 --> 00:11:51,300
So that's pretty significant and as you can expect the p value is

95
00:11:51,610 --> 00:11:55,519
fairly small, almost zero for two coefficients.

96
00:11:56,120 --> 00:12:05,399
Therefore, we can safely reject the null hypothesis and we can conclude that our coefficient values are statistically significant.

97
00:12:09,639 --> 00:12:14,419
Similarly, we can also define 95% CI, competency-inheritance for the coefficients.

98
00:12:14,419 --> 00:12:18,730
To calculate that, the formula is given by this.

99
00:12:18,759 --> 00:12:22,340
Mean of the coefficient plus minus two

100
00:12:23,259 --> 00:12:29,309
or actually it's 1.96 times the standard error and the standard error is given here.

101
00:12:29,309 --> 00:12:36,149
We can also define 95% confidence interval for the regression line.

102
00:12:36,149 --> 00:12:42,439
That means 95% of time my regression line will lie within this orange shaded region.

103
00:12:42,439 --> 00:12:47,899
And 95% prediction interval, which is for the sample points.

104
00:12:47,899 --> 00:12:54,429
That means 95% of time the sample points will be within this blue shaded region.

105
00:12:56,120 --> 00:13:05,360
This analysis can be handy when you have some outliers and these outliers may be good to remove to have better regression.

106
00:13:07,909 --> 00:13:13,720
Ok, so let's talk about how we measure the error from the test data and the training data and how to compare them.

107
00:13:16,889 --> 00:13:26,779
So we talked about this popular error measure so we're going to use them or one of them and let's say we have original training data that we used to use

108
00:13:27,220 --> 00:13:28,790
to fit the model.

109
00:13:29,600 --> 00:13:34,779
Instead of using all of them to fit the model, we're going to set aside some data.

110
00:13:34,879 --> 00:13:37,190
Some portion of data is test data.

111
00:13:40,100 --> 00:13:43,259
And the rest we're going to use it for training.

112
00:13:45,389 --> 00:13:53,159
train set, test set, and each of them have feature and label.

113
00:13:53,460 --> 00:13:58,519
So train set has feature x train and label y train.

114
00:13:59,720 --> 00:14:05,240
and the test set has feature test and label test.

115
00:14:07,920 --> 00:14:11,019
So using the train set, we're gonna fit the model.

116
00:14:11,430 --> 00:14:15,970
So model initially had undefined coefficient values.

117
00:14:17,210 --> 00:14:24,639
So we're gonna do fit and then supply our train data, X train and Y train.

118
00:14:25,639 --> 00:14:28,759
And this fit function will determine the coefficient values.

119
00:14:29,890 --> 00:14:37,080
And now this model internally will have optimal coefficient values.

120
00:14:37,860 --> 00:14:40,230
So with that, we're gonna predict this time.

121
00:14:41,700 --> 00:14:42,860
So dot predict.

122
00:14:44,360 --> 00:14:46,810
And for prediction, we don't need a label.

123
00:14:47,740 --> 00:14:50,620
So we're gonna put train data.

124
00:14:51,220 --> 00:14:53,920
Then it becomes yprediction.

125
00:14:55,480 --> 00:14:58,570
So I'm gonna put hat here, but from the training data.

126
00:14:59,770 --> 00:15:01,050
We can do the similar.

127
00:15:04,220 --> 00:15:16,580
with the already fitted model and dot predict and supply test data instead this time and this will give Y prediction from the test data.

128
00:15:16,690 --> 00:15:20,830
So what do we do with this?

129
00:15:21,000 --> 00:15:22,480
So this value and this value.

130
00:15:23,430 --> 00:15:28,629
We can measure the error between the prediction value and and a label.

131
00:15:28,820 --> 00:15:31,139
So for example, so

132
00:15:32,009 --> 00:15:54,790
training MSC or error for the training data is going to be MSC of Y true value for the training label, so which is this one, and the Y prediction value from the training data from this one.

133
00:15:56,330 --> 00:15:59,460
So that's going to be our train error.

134
00:15:59,540 --> 00:16:01,810
So for example this one.

135
00:16:03,050 --> 00:16:06,050
And we can calculate similarly MSA for test data.

136
00:16:07,270 --> 00:16:19,790
So MSA test TE is going to be MSA y test the true value and then the y prediction from the test data.

137
00:16:21,620 --> 00:16:25,140
And this value is this for example.

138
00:16:26,100 --> 00:16:31,040
So it's very common that the test error is a slightly larger than the train error.

139
00:16:32,310 --> 00:16:39,950
Or if the data were pretty homogeneous and your model is doing well then train error and test error could be similar value.

140
00:16:42,030 --> 00:16:49,810
We'll say later that if my model is overparameterized, then it doesn't do very well in the test data.

141
00:16:50,490 --> 00:16:56,320
And it's an important way to figure out whether my model is overparameterized or not.

142
00:16:56,740 --> 00:16:58,050
So we'll talk about that later.

143
00:17:01,120 --> 00:17:04,510
In summary, we talked about how we determine the coefficients.

144
00:17:05,110 --> 00:17:07,960
So we talked about least squares method.

145
00:17:11,119 --> 00:17:14,480
method, which minimizes the residual sum of squares.

146
00:17:15,329 --> 00:17:21,680
So we talked about what the RSS is, what the mean squared error is, and bunch of other error metrics.

147
00:17:22,910 --> 00:17:26,029
And we also talked about the goodness of the model fit.

148
00:17:26,650 --> 00:17:31,549
So we talked about R squared and how R squared is derived.

149
00:17:31,609 --> 00:17:36,140
So we derived it using RSS and TSS.

150
00:17:37,720 --> 00:17:43,940
And we also talked about some things that we need to be careful when we interpret the R squared value.

151
00:17:46,089 --> 00:17:48,680
We also talked about significance of the coefficients.

152
00:17:48,849 --> 00:17:55,009
So we talked about standard error of the coefficients, how they are derived or can be determined.

153
00:17:55,950 --> 00:18:05,230
And then we talked about t-score and the p-value and hypothesis testing to say whether the coefficients values are significant or not.

154
00:18:05,230 --> 00:18:08,730
And then we talked about confidence intervals as well.

155
00:18:08,730 --> 00:18:16,640
And lastly, we talked about how to measure the error for training data and test data and how to compare them.

156
00:18:18,319 --> 00:18:21,160
And that's it for the simple linear regression.

157
00:18:21,519 --> 00:18:30,990
And in the next video, we're going to talk about what happens when we add more model complexity such as higher order terms or other features into the model.

