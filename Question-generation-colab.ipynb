{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Paths\n",
        "local_file_path = \"/content/sentences.txt\"\n",
        "drive_folder = \"/content/drive/MyDrive/question-answer\"\n",
        "drive_file_path = os.path.join(drive_folder, \"sentences.txt\")\n",
        "drive_sentences_path = os.path.join(drive_folder, \"sentences.txt\")\n",
        "\n",
        "# Make sure Drive folder exists\n",
        "os.makedirs(drive_folder, exist_ok=True)\n",
        "\n",
        "# Copy file to Drive\n",
        "if os.path.exists(local_file_path):\n",
        "    shutil.copy(local_file_path, drive_file_path)\n",
        "    print(f\"'sentences.txt' copied to Google Drive at: {drive_file_path}\")\n",
        "else:\n",
        "    print(\"'sentences.txt' not found in Colab. Please upload it first.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtkTQVfdO1RD",
        "outputId": "5854a237-962d-49ac-fecd-6cd44dd7995e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "'sentences.txt' copied to Google Drive at: /content/drive/MyDrive/question-answer/sentences.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izjhCxL86otB",
        "outputId": "768632a4-01ac-425a-dcf3-0102b76994e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ 'generated_questions.txt' already exists at: /content/drive/MyDrive/question-answer/generated_questions.txt\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. 🚗 Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. 📂 Define paths\n",
        "drive_folder = \"/content/drive/MyDrive/question-answer\"\n",
        "drive_sentences_path = os.path.join(drive_folder, \"sentences.txt\")\n",
        "drive_output_path = os.path.join(drive_folder, \"generated_questions.txt\")\n",
        "\n",
        "# 3. ✅ Check if output already exists\n",
        "if os.path.exists(drive_output_path):\n",
        "    print(f\"✅ 'generated_questions.txt' already exists at: {drive_output_path}\")\n",
        "else:\n",
        "    print(\"🚀 File not found. Starting question generation...\")\n",
        "\n",
        "    # 4. ⚡ Setup device and pipeline\n",
        "    device = 0 if torch.cuda.is_available() else -1\n",
        "    qg_pipeline = pipeline(\"text2text-generation\", model=\"valhalla/t5-base-qg-hl\", device=device)\n",
        "\n",
        "    # 5. 📖 Read sentences from Drive\n",
        "    with open(drive_sentences_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        sentences = [line.strip() for line in file if line.strip()]\n",
        "\n",
        "    # 6. ✍️ Generate questions and save to Drive\n",
        "    with open(drive_output_path, \"w\", encoding=\"utf-8\") as out_file:\n",
        "        for sentence in tqdm(sentences, desc=\"Generating Questions\", unit=\"sentence\"):\n",
        "            questions = qg_pipeline(sentence, max_length=128, num_return_sequences=1)\n",
        "            for q in questions:\n",
        "                out_file.write(q[\"generated_text\"] + \"\\n\")\n",
        "\n",
        "    print(f\"✅ Question generation complete! Saved to: {drive_output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Define paths\n",
        "drive_folder = \"/content/drive/MyDrive/question-answer\"\n",
        "questions_file = os.path.join(drive_folder, \"generated_questions.txt\")\n",
        "embeddings_file = os.path.join(drive_folder, \"questions_embeddings.npy\")\n",
        "questions_list_file = os.path.join(drive_folder, \"questions_list.txt\")\n",
        "\n",
        "# Load the model\n",
        "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Check if embeddings and questions list already exist\n",
        "if os.path.exists(embeddings_file) and os.path.exists(questions_list_file):\n",
        "    print(\"✅ Found existing embeddings and questions list. Loading from Drive...\")\n",
        "\n",
        "    question_embeddings = np.load(embeddings_file)\n",
        "\n",
        "    with open(questions_list_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        questions = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "else:\n",
        "    print(\"🔍 Embeddings not found. Generating from questions...\")\n",
        "\n",
        "    # Load questions\n",
        "    with open(questions_file, \"r\", encoding=\"utf-8\") as file:\n",
        "        questions = [line.strip() for line in file if line.strip()]\n",
        "\n",
        "    # Encode questions\n",
        "    question_embeddings = np.array(model.encode(questions)).astype(\"float32\")\n",
        "\n",
        "    # Save embeddings and questions\n",
        "    np.save(embeddings_file, question_embeddings)\n",
        "\n",
        "    with open(questions_list_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\\n\".join(questions))\n",
        "\n",
        "    print(f\"✅ Embeddings and questions saved to: {drive_folder}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgQWtdnv93jU",
        "outputId": "5bf7f8f4-16d0-40b5-db03-3bf185134e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Found existing embeddings and questions list. Loading from Drive...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. 📁 Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. 📂 Define paths inside Drive\n",
        "drive_folder = \"/content/drive/MyDrive/question-answer\"\n",
        "embeddings_path = os.path.join(drive_folder, \"questions_embeddings.npy\")\n",
        "questions_path = os.path.join(drive_folder, \"questions_list.txt\")\n",
        "\n",
        "# 3. 🤖 Load model\n",
        "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# 4. 📥 Load embeddings and questions\n",
        "question_embeddings = np.load(embeddings_path)\n",
        "\n",
        "with open(questions_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    questions = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "# 5. 🔍 Similarity function\n",
        "def is_question_clear(query):\n",
        "    \"\"\"Check if a given question is clear based on similarity to existing questions.\"\"\"\n",
        "    query_embedding = model.encode([query]).astype(\"float32\")\n",
        "    similarities = cosine_similarity(query_embedding, question_embeddings)[0]\n",
        "    max_similarity = np.max(similarities)\n",
        "    return max_similarity >= 0.6, max_similarity\n",
        "\n",
        "# 6. 💬 Interactive input loop\n",
        "while True:\n",
        "    test_question = input(\"\\nEnter your question (or type 'exit' to quit): \").strip()\n",
        "\n",
        "    if test_question.lower() == \"exit\":\n",
        "        print(\"👋 Exiting...\")\n",
        "        break\n",
        "\n",
        "    clear, similarity_score = is_question_clear(test_question)\n",
        "\n",
        "    if clear:\n",
        "        print(f\"The question is clear (Similarity: {similarity_score:.2f})\")\n",
        "    else:\n",
        "        print(f\"The question is unclear (Similarity: {similarity_score:.2f})\")\n"
      ],
      "metadata": {
        "id": "VyM0dv2t-Cj-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "259d47a0-b25b-48e5-9162-a89db813437e"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ]
}